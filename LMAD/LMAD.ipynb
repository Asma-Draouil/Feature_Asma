{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL du site web\n",
    "url = 'https://www.esb.tn/programmes/licences/licence-en-mathematiques-appliquees/'\n",
    "# Charger le contenu HTML depuis la page web\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Vérifier que la requête s'est bien passée\n",
    "html = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parser le HTML avec BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objectifs trouvés:\n",
      "Le monde est devenu mathématique. La décision repose sur l’analyse de données de plus en plus massives – Big Data.\n",
      "LaLicence en Mathématiques Appliquées à l’Analyse des Données et à l’Aide à la Décisionfait appel à des outils d’intelligence artificielle et de machine learning et à des compétences et savoir-faire mathématiques et statistiques.\n",
      "Cette licence s’adresse aux bacheliers en mathématiques, informatique, sciences expérimentales, sciences techniques et tout autre diplôme équivalent.\n",
      "Les objectifs ont été enregistrés dans 'objectif_programme.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\AppData\\Local\\Temp\\ipykernel_20064\\2669019199.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  objectif_section = soup.find('h3', text=\"Objectifs\")\n"
     ]
    }
   ],
   "source": [
    "# Trouver la section \"Objectifs\"\n",
    "objectif_section = soup.find('h3', text=\"Objectifs\")\n",
    "\n",
    "if objectif_section:\n",
    "    # Trouver les trois paragraphes après l'en-tête \"Objectifs\"\n",
    "    objectif_paragraphs = objectif_section.find_all_next('p', limit=3)\n",
    "\n",
    "    if objectif_paragraphs:\n",
    "        # Extraire le texte de chaque paragraphe et les stocker dans une liste\n",
    "        objectif_texts = [para.get_text(strip=True) for para in objectif_paragraphs]\n",
    "        print(\"Objectifs trouvés:\")\n",
    "        for text in objectif_texts:\n",
    "            print(text)\n",
    "\n",
    "        # Enregistrer les objectifs dans un fichier CSV\n",
    "        with open('objectif_programme.csv', mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Objectif\"])  # En-tête du fichier\n",
    "            for text in objectif_texts:\n",
    "                writer.writerow([text])  # Ligne avec chaque paragraphe trouvé\n",
    "\n",
    "        print(\"Les objectifs ont été enregistrés dans 'objectif_programme.csv'.\")\n",
    "    else:\n",
    "        print(\"Aucun paragraphe trouvé après 'Objectifs'.\")\n",
    "else:\n",
    "    print(\"Objectif non trouvé sur la page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu trouvé :\n",
      "MATHÉMATIQUES ET STATISTIQUES :\n",
      "Analyse des données, Optimisation discrète et convexe,Actuariat, Analyse statistique, Régression et modèlesprédictifs, Processus stochastique\n",
      "INFORMATIQUE DÉCISIONNELLE :\n",
      "Programmation (Python), Bases de données, DataWarehouse, Data Mining, Big Data, Intelligence Artificielle, Machine Learning\n",
      "SOFT SKILLS :\n",
      "Séminaires, Développement personnel, Business Games, Langues, etc.\n",
      "PROJET PROFESSIONNEL :\n",
      "Stages, PFE, Projets intégrés, Visites d’entreprises, Ateliers, Études de cas, etc.\n",
      "Le contenu a été enregistré dans 'contenu_programme.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\AppData\\Local\\Temp\\ipykernel_20064\\2090555182.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  contenu_section = soup.find('h3', text=\"Contenu\")\n"
     ]
    }
   ],
   "source": [
    "# Trouver la section \"Contenu\"\n",
    "contenu_section = soup.find('h3', text=\"Contenu\")\n",
    "\n",
    "if contenu_section:\n",
    "    # Extraire les éléments suivants (listes et paragraphes) après \"Contenu\"\n",
    "    contenu_list = contenu_section.find_all_next(['ul', 'p'], limit=8)\n",
    "\n",
    "    # Liste pour stocker les données extraites\n",
    "    contenu_data = []\n",
    "\n",
    "    for tag in contenu_list:\n",
    "        contenu_data.append(tag.get_text(strip=True))\n",
    "\n",
    "    # Afficher les résultats extraits\n",
    "    print(\"Contenu trouvé :\")\n",
    "    for item in contenu_data:\n",
    "        print(item)\n",
    "\n",
    "    # Enregistrer dans un fichier CSV\n",
    "    with open('contenu_programme.csv', mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Contenu\"])  # En-tête du fichier\n",
    "        for item in contenu_data:\n",
    "            writer.writerow([item])  # Écriture de chaque ligne\n",
    "\n",
    "    print(\"Le contenu a été enregistré dans 'contenu_programme.csv'.\")\n",
    "else:\n",
    "    print(\"Section 'Contenu' non trouvée sur la page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compétences trouvées :\n",
      "Aider les organisations à créer de la valeur ou à innover dans leurs secteurs respectifs à partir des décisions fondées sur des rigueurs mathématiques et inférer par des techniques statistiques.\n",
      "Maîtriser l’analyse et le traitement des données massives (Big Data).\n",
      "Maîtriser les langages de programmation dans le domaine de la Data Science.\n",
      "Évaluer la rentabilité et gérer le risque pour les produits ﬁnanciers.\n",
      "Mettre en œuvre les méthodes d’exploration et d’exploitation des données.\n",
      "Organiser et superviser des enquêtes et des sondages.\n",
      "Aider à la transformation digitale des entreprises.\n",
      "Les compétences ont été enregistrées dans 'competences_programme.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\AppData\\Local\\Temp\\ipykernel_20064\\3385109899.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  competences_section = soup.find('h3', text=\"Compétences\")\n"
     ]
    }
   ],
   "source": [
    "# Trouver la section contenant les compétences (liste <ul> avec <li>)\n",
    "competences_section = soup.find('h3', text=\"Compétences\")\n",
    "\n",
    "if competences_section:\n",
    "    # Extraire la liste des compétences après la section \"Compétences\"\n",
    "    competences_list = competences_section.find_all_next('ul', limit=1)  # Trouver la première <ul> après l'en-tête\n",
    "\n",
    "    # Liste pour stocker les données extraites\n",
    "    competences_data = []\n",
    "\n",
    "    for ul_tag in competences_list:\n",
    "        # Trouver toutes les balises <li> dans la <ul> et ajouter le texte à la liste\n",
    "        for li_tag in ul_tag.find_all('li'):\n",
    "            competences_data.append(li_tag.get_text(strip=True))\n",
    "\n",
    "    # Afficher les résultats extraits\n",
    "    print(\"Compétences trouvées :\")\n",
    "    for item in competences_data:\n",
    "        print(item)\n",
    "\n",
    "    # Enregistrer dans un fichier CSV\n",
    "    with open('competences_programme.csv', mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Compétences\"])  # En-tête du fichier\n",
    "        for item in competences_data:\n",
    "            writer.writerow([item])  # Écriture de chaque compétence\n",
    "\n",
    "    print(\"Les compétences ont été enregistrées dans 'competences_programme.csv'.\")\n",
    "else:\n",
    "    print(\"Section 'Compétences' non trouvée sur la page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métiers trouvés :\n",
      "Analyste de Données\n",
      "Chargé d’Études Actuarielles en Assurances\n",
      "Front Office Marché Financier\n",
      "Trader Analyste de Crédit et Risque Bancaire\n",
      "Data Miner / Data Scientist\n",
      "Expert en BI\n",
      "Business Analyst\n",
      "Statisticien\n",
      "Les Métiers ont été enregistrées dans 'metiers_programme.csv'.\n",
      "Secteurs d’activité trouvés :\n",
      "Sociétés de services informatique\n",
      "Éditeurs de logiciels\n",
      "Banques et Assurances\n",
      "Entreprises commerciales\n",
      "Entreprises industrielles\n",
      "Les Secteurs d’activité ont été enregistrées dans 'secteurs_activite_programme.csv'.\n",
      "Partenariats professionnels trouvés :\n",
      "> Entreprises de services numériques\n",
      "> Banques et Assurances\n",
      "> Sociétés de conseil\n",
      "Les Partenariats professionnels ont été enregistrées dans 'partenariats_programme.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asma\\AppData\\Local\\Temp\\ipykernel_20064\\3584973596.py:4: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  section = soup.find('h3', text=section_tag)\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour extraire les données et les enregistrer dans un fichier CSV\n",
    "def extraire_et_enregistrer(section_name, section_tag, file_name, limit=None):\n",
    "    # Trouver la section spécifique (par exemple, \"Métiers\", \"Secteurs d’activité\", \"Partenariats professionnels\")\n",
    "    section = soup.find('h3', text=section_tag)\n",
    "    if section:\n",
    "        # Extraire la liste suivante ou les paragraphes\n",
    "        if section_tag == \"Partenariats professionnels\":\n",
    "            # Si la section est \"Partenariats professionnels\", les éléments sont des <p> avec une limite optionnelle\n",
    "            data_list = section.find_all_next('p', limit=limit)\n",
    "            data = [item.get_text(strip=True) for item in data_list if item.get_text(strip=True)]\n",
    "        else:\n",
    "            # Pour les autres sections, les éléments sont dans une liste <ul><li>\n",
    "            data_list = section.find_all_next('ul', limit=1)\n",
    "            data = []\n",
    "            for ul_tag in data_list:\n",
    "                for li_tag in ul_tag.find_all('li'):\n",
    "                    data.append(li_tag.get_text(strip=True))\n",
    "\n",
    "        # Afficher les résultats extraits\n",
    "        print(f\"{section_name} trouvés :\")\n",
    "        for item in data:\n",
    "            print(item)\n",
    "\n",
    "        # Enregistrer dans un fichier CSV\n",
    "        with open(file_name, mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([section_name])  # En-tête du fichier\n",
    "            for item in data:\n",
    "                writer.writerow([item])  # Écriture de chaque ligne\n",
    "\n",
    "        print(f\"Les {section_name} ont été enregistrées dans '{file_name}'.\")\n",
    "    else:\n",
    "        print(f\"Section '{section_tag}' non trouvée sur la page.\")\n",
    "\n",
    "# Extraire et enregistrer les données pour chaque section\n",
    "extraire_et_enregistrer(\"Métiers\", \"Métiers\", \"metiers_programme.csv\")\n",
    "extraire_et_enregistrer(\"Secteurs d’activité\", \"Secteurs d’activité\", \"secteurs_activite_programme.csv\")\n",
    "extraire_et_enregistrer(\"Partenariats professionnels\", \"Partenariats professionnels\", \"partenariats_programme.csv\", limit=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les matières du Semestre 1 ont été ajoutées au fichier CSV.\n",
      "Les matières du Semestre 2 ont été ajoutées au fichier CSV.\n",
      "Les matières du Semestre 3 ont été ajoutées au fichier CSV.\n",
      "Les matières du Semestre 4 ont été ajoutées au fichier CSV.\n",
      "Les matières du Semestre 5 ont été ajoutées au fichier CSV.\n",
      "Les matières du Semestre 6 ont été ajoutées au fichier CSV.\n"
     ]
    }
   ],
   "source": [
    "def extraire_matieres_par_semestre(soup):\n",
    "    # Trouver l'accordion contenant les semestres\n",
    "    accordion = soup.find('div', class_='elementor-accordion')\n",
    "    if accordion:\n",
    "        semestres = accordion.find_all('div', class_='elementor-accordion-item')\n",
    "\n",
    "        # Ouvrir un fichier CSV pour écrire toutes les matières\n",
    "        with open('matieres_par_semestre.csv', mode='w', newline='', encoding='utf-8-sig') as file:\n",
    "            writer = csv.writer(file)\n",
    "            \n",
    "            # Ajouter un en-tête pour le CSV\n",
    "            writer.writerow(['Semestre', 'Matière'])\n",
    "\n",
    "            # Extraire les matières par semestre et les enregistrer dans le fichier CSV\n",
    "            for semestre in semestres:\n",
    "                semestre_title = semestre.find('a').get_text(strip=True)\n",
    "                semestre_content = semestre.find('div', class_='elementor-tab-content')\n",
    "\n",
    "                if semestre_content:\n",
    "                    ul = semestre_content.find('ul')\n",
    "                    if ul:\n",
    "                        for li in ul.find_all('li'):\n",
    "                            matiere = li.get_text()\n",
    "                            writer.writerow([semestre_title, matiere])\n",
    "\n",
    "                    print(f\"Les matières du {semestre_title} ont été ajoutées au fichier CSV.\")\n",
    "    else:\n",
    "        print(\"Accordion non trouvé.\")\n",
    "\n",
    "\n",
    "# Extraire les matières par semestre\n",
    "extraire_matieres_par_semestre(soup)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
